{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the dictionary\n",
    "categories = [\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\", \"ADV\", \"ADP\", \"PRON\", \"DET\", \"CONJ\", \"PART\", \"PRON_WH\", \"PART_NEG\", \"NUM\", \"X\"]\n",
    "\n",
    "# Data processing \n",
    "def data_process(a1, a2):\n",
    "\n",
    "    # Giving output as two lists for each annotator\n",
    "    data = [[], []]\n",
    "\n",
    "    # Passing through the annotator lists\n",
    "    for i in range(len(a1)):\n",
    "\n",
    "        # Annotator 1 - list of words and label indices\n",
    "        w_1 = []\n",
    "        an_1 = []\n",
    "\n",
    "        d_1 = json.loads(a1[i])\n",
    "\n",
    "        for j in d_1:\n",
    "            w_1.append(j[\"text\"].strip())\n",
    "            try:\n",
    "                c = (j[\"labels\"][0])\n",
    "                an_1.append(categories.index(c))\n",
    "            except:\n",
    "                an_1.append(13)\n",
    "    \n",
    "        # Annotator 2 - list of words and label indices.\n",
    "        w_2 = []\n",
    "        an_2 = []\n",
    "\n",
    "        d_2 = json.loads(a2[i])\n",
    "\n",
    "        for k in d_2:\n",
    "            w_2.append(k[\"text\"].strip())\n",
    "            try:\n",
    "                c = (k[\"labels\"][0])\n",
    "                an_2.append(categories.index(c))\n",
    "            except:\n",
    "                an_2.append(13)\n",
    "\n",
    "        # Comparing the words and appending the indices for final comparison.\n",
    "        for l in range(len(w_1)):\n",
    "            try:\n",
    "                m = w_2.index(w_1[l])\n",
    "                data[0].append(an_1[l])\n",
    "                data[1].append(an_2[m])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8430125989002065\n"
     ]
    }
   ],
   "source": [
    "# Reading the csv files as dataframes\n",
    "df_1 = pd.read_csv(\"A1_NLP.csv\")\n",
    "df_2 = pd.read_csv(\"A2_NLP.csv\")\n",
    "\n",
    "# Passing the data as lists\n",
    "data = data_process(df_1[\"label\"].to_list(), df_2[\"label\"].to_list())\n",
    "\n",
    "# print(data[0])\n",
    "# print(data[1])\n",
    "\n",
    "# Printing the cohen kappa score from the sklearn.metrics module.\n",
    "print(cohen_kappa_score(data[0], data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
